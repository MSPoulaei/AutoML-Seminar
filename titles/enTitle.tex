% !TeX root=main.tex
% در این فایل، عنوان پایان‌نامه، مشخصات خود و چکیده پایان‌نامه را به انگلیسی، وارد کنید.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\baselineskip=.6cm
\begin{latin}
\latinuniversity{Iran University of Science and Technology}
\latinfaculty{Computer Engineering Department}
\latinsubject{Computer Engineering-Artificial Intelligence}
% \latinfield{Artificial Intelligence}
\latintitle{Review of agent-based large language models in neural architecture search and hyperparameter optimization}
\firstlatinsupervisor{Dr. MohammadReza Mohammadi}
\secondlatinsupervisor{Dr. Sauleh Etemadi}
% \firstlatinadvisor{First Advisor}
%\secondlatinadvisor{Second Advisor}
\latinname{Mohammad Sadegh}
\latinsurname{Poulaei Moziraji}
\latinthesisdate{November 2025}
\latinkeywords{Automated Machine Learning, Large Language Models, Agent-Based Systems,Hyperparameter Optimization, Neural Architecture Search, Retrieval-Augmented Generation, In-Context Learning, Transfer Learning}
\en-abstract{
    Traditional AutoML approaches using Bayesian optimization and evolutionary algorithms lack interpretability and struggle to leverage domain knowledge. Large Language Models (LLMs) with capabilities in natural language understanding, reasoning, and code generation offer a transformative paradigm shift. This seminar explores how LLM-based agents can revolutionize AutoML systems by acting as intelligent, context-aware, and adaptive agents rather than blind optimizers. This work systematically reviews recent LLM-based AutoML approaches from three perspectives: (1) Agent Architecture: single-agent systems (direct optimization, evolutionary operators, workflow controllers) versus multi-agent systems (role-based collaboration, hierarchical coordination) (2) Knowledge Sources: internal knowledge (optimization history, in-context learning) versus external retrieval (literature extraction, model repositories) and (3) Output Formats: structured configurations, code generation, tree representations, and hybrid approaches. Analysis reveals an even split between single-agent and multi-agent architectures, with most systems relying on internal knowledge and few leveraging external knowledge through retrieval-augmented generation. Output formats show high diversity, with hybrid approaches balancing machine-readability and expressiveness. The seminar identifies critical open problems and future directions, including resource-constrained optimization, advanced knowledge integration, and multi-agent frameworks. A thesis proposal is presented for designing an agent-based AutoML system for model selection and fine-tuning in transfer learning with limited data.
}
\latinfirstPage
\end{latin}
