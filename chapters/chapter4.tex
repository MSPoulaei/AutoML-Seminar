
\chapter{نتیجه گیری و کارهای آینده}
\thispagestyle{empty}
\section{نتیجه‌گیری}
این گزارش به بررسی و تحلیل رویکردهای نوظهور در یادگیری ماشین خودکار پرداخت که از قابلیت‌های مدل‌های زبانی بزرگ در قالب سیستم‌های عامل-محور بهره می‌برند. مرور ادبیات نشان داد که این حوزه به سرعت در حال فاصله گرفتن از بهینه‌سازهای جعبه‌سیاه سنتی و حرکت به سوی روندهای بر اساس دانش، تفسیرپذیر و خودمختار است.

ما روش‌های موجود را از سه منظر کلیدی طبقه‌بندی کردیم: معماری عامل (تک‌عاملی در برابر چندعاملی)، منابع دانش (درونی در برابر بیرونی) و قالب خروجی (ساختاریافته، کد، یا ترکیبی).

یافته‌ها حاکی از آن است که عامل‌های تک‌عاملی، به‌ویژه آن‌هایی که از دستوردهی تکراری یا عملگرهای تکاملی استفاده می‌کنند، برای بهینه‌سازی ابرپارامترها و جستجوی معماری عصبی محدود مؤثر هستند. در مقابل، معماری‌های چندعاملی با تفکیک نقش (مانند پژوهشگر و توسعه‌دهنده)، پتانسیل بیشتری برای مدیریت خطوط لوله پیچیده و بلند-افق یادگیری ماشین خودکار از خود نشان می‌دهند.

ادغام تولید تقویت‌شده با بازیابی یک پیشرفت کلیدی است که به عامل‌ها اجازه می‌دهد تا از دانش ایستای خود فراتر رفته و از ادبیات پژوهشی، \persianfootnote{مخازن کد}\LTRfootnote{code repositories} و \persianfootnote{نتایج آزمایش‌های گذشته}\LTRfootnote{past experimental results} برای اتخاذ تصمیمات آگاهانه‌تر استفاده کنند. در نهایت، قالب خروجی نشان‌دهنده یک توازن میان \persianfootnote{خوانایی ماشینی}\LTRfootnote{machine-readability} (مانند JSON) و بیانگری (مانند تولید کد کامل) است، که رویکردهای ترکیبی به عنوان راه‌حلی میانه در حال ظهور هستند. در مجموع، یادگیری ماشین خودکار عامل-محور یک حوزه تحقیقاتی بسیار پویا است که نویدبخش خودکارسازی هوشمندانه‌تر و کارآمدتر فرایندهای علم داده است.

\section{مسائل باز و کارهای قابل انجام}
علی‌رغم پیشرفت‌های هیجان‌انگیز، چالش‌ها و مسائل باز متعددی در این حوزه وجود دارد که نیازمند پژوهش‌های آتی است:

% \begin{itemize}
%     \item \textbf{\persianfootnote{ارزیابی و محک‌زنی}\LTRfootnote{Evaluation and Benchmarking}:} در حال حاضر، \persianfootnote{محک‌های}\LTRfootnote{benchmarks} استاندارد و جامعی برای ارزیابی \persianfootnote{عامل‌های}\LTRfootnote{agents} یادگیری ماشین خودکار وجود ندارد. معیارهای ارزیابی باید فراتر از \persianfootnote{کارایی نهایی}\LTRfootnote{final performance} مدل باشند و مواردی چون \persianfootnote{کارایی نمونه}\LTRfootnote{sample efficiency} (تعداد \persianfootnote{ارزیابی‌های}\LTRfootnote{evaluations} گران‌قیمت)، \persianfootnote{هزینه استنتاج}\LTRfootnote{inference cost} مدل زبانی بزرگ، \persianfootnote{تفسیرپذیری}\LTRfootnote{interpretability} فرایند جستجو و \persianfootnote{استحکام}\LTRfootnote{robustness} عامل در برابر \persianfootnote{ورودی‌های نویزی}\LTRfootnote{noisy inputs} یا \persianfootnote{وظایف خارج از توزیع}\LTRfootnote{out-of-distribution tasks} را نیز در بر گیرند.

%     \item \textbf{\persianfootnote{کارایی محاسباتی و هزینه}\LTRfootnote{Computational Efficiency and Cost}:} استفاده از مدل‌های زبانی بزرگ قدرتمند (مانند GPT-4) در یک \persianfootnote{حلقه بهینه‌سازی}\LTRfootnote{optimization loop} تکراری می‌تواند بسیار پرهزینه باشد. پژوهش در مورد چگونگی کاهش \persianfootnote{هزینه}\LTRfootnote{cost} (مثلاً با استفاده از \persianfootnote{مدل‌های کوچک‌تر}\LTRfootnote{smaller models} برای \persianfootnote{تصمیمات ساده‌تر}\LTRfootnote{simpler decisions}، \persianfootnote{تقطیر دانش}\LTRfootnote{knowledge distillation}، یا \persianfootnote{ذخیره‌سازی هوشمند}\LTRfootnote{intelligent caching} \persianfootnote{استدلال‌ها}\LTRfootnote{reasoning steps}) ضروری است.

%     \item \textbf{\persianfootnote{قابلیت اطمینان و توهم}\LTRfootnote{Reliability and Hallucination}:} \persianfootnote{عامل‌ها}\LTRfootnote{Agents} ممکن است در \persianfootnote{استدلال}\LTRfootnote{reasoning} خود دچار \persianfootnote{خطا}\LTRfootnote{errors} شوند، \persianfootnote{کد}\LTRfootnote{code} \persianfootnote{ناقص}\LTRfootnote{buggy} تولید کنند، یا \persianfootnote{مفاهیم}\LTRfootnote{concepts} را به اشتباه تفسیر کنند (\persianfootnote{توهم}\LTRfootnote{hallucination}). توسعه \persianfootnote{مکانیزم‌های خود-اصلاحی}\LTRfootnote{self-correction mechanisms}، \persianfootnote{اعتبارسنجی دقیق}\LTRfootnote{rigorous validation} \persianfootnote{خروجی‌های}\LTRfootnote{outputs} عامل، و \persianfootnote{حلقه‌های بازخورد انسانی}\LTRfootnote{Human-in-the-Loop (HITL)} برای افزایش \persianfootnote{قابلیت اطمینان}\LTRfootnote{reliability} سیستم‌ها حیاتی است.

%     \item \textbf{\persianfootnote{مدیریت حافظه و وظایف بلند-افق}\LTRfootnote{Memory Management and Long-Horizon Tasks}:} \persianfootnote{خطوط لوله}\LTRfootnote{Pipelines} یادگیری ماشین خودکار می‌توانند بسیار طولانی باشند. \persianfootnote{عامل‌ها}\LTRfootnote{Agents} نیاز به \persianfootnote{حافظه}\LTRfootnote{memory} \persianfootnote{بلندمدت}\LTRfootnote{long-term} کارآمد دارند تا \persianfootnote{تجربیات گذشته}\LTRfootnote{past experiences} را به خاطر بسپارند، \persianfootnote{زمینه}\LTRfootnote{context} را حفظ کنند و از \persianfootnote{تکرار خطاها}\LTRfootnote{repeating mistakes} بپرهیزند. این امر با \persianfootnote{محدودیت پنجره زمینه}\LTRfootnote{context window limitations} مدل‌های زبانی بزرگ در تضاد است و نیازمند \persianfootnote{معماری‌های حافظه}\LTRfootnote{memory architectures} پیشرفته (مانند \persianfootnote{حافظه‌های سلسله‌مراتبی}\LTRfootnote{hierarchical memory} یا \persianfootnote{ترکیبی}\LTRfootnote{hybrid}) می‌باشد.

%     \item \textbf{\persianfootnote{یادگیری از بازخورد محیطی}\LTRfootnote{Learning from Environmental Feedback}:} چگونگی \persianfootnote{یادگیری}\LTRfootnote{learning} عامل از \persianfootnote{بازخورد}\LTRfootnote{feedback} (مثلاً نتایج \persianfootnote{اعتبارسنجی}\LTRfootnote{validation} یک \persianfootnote{پیکربندی}\LTRfootnote{configuration} یا \persianfootnote{خطای اجرای کد}\LTRfootnote{code execution error}) برای \persianfootnote{پالایش}\LTRfootnote{refine} \persianfootnote{سیاست}\LTRfootnote{policy} \persianfootnote{جستجوی}\LTRfootnote{search} خود، یک \persianfootnote{مسئله باز}\LTRfootnote{open question} است. این موضوع به \persianfootnote{یادگیری تقویتی}\LTRfootnote{Reinforcement Learning} مرتبط است، اما \persianfootnote{فضای حالت و اقدام}\LTRfootnote{state-action space} در یادگیری ماشین خودکار بسیار پیچیده‌تر و \persianfootnote{پربعدتر}\LTRfootnote{higher-dimensional} است.
% \end{itemize}

\section{معرفی موضوع مورد نظر برای پایان نامه}
با توجه به \persianfootnote{مسائل باز}\LTRfootnote{open problems} شناسایی شده، یک \persianfootnote{موضوع پژوهشی}\LTRfootnote{research topic} جذاب برای پایان‌نامه می‌تواند «توسعه یک چارچوب \persianfootnote{چندعاملی}\LTRfootnote{Multi-Agent} \persianfootnote{خود-اصلاحگر}\LTRfootnote{Self-Correcting} برای \persianfootnote{جستجوی معماری عصبی}\LTRfootnote{Neural Architecture Search} با \persianfootnote{تقویت دانش}\LTRfootnote{Knowledge Augmentation}» باشد.

\persianfootnote{هدف اصلی}\LTRfootnote{Main objective} این پژوهش، طراحی سیستمی متشکل از چندین عامل تخصصی (مثلاً \persianfootnote{عامل تحلیلگر نیازمندی}\LTRfootnote{Requirement Analyst Agent}، \persianfootnote{عامل معمار}\LTRfootnote{Architect Agent}، \persianfootnote{عامل ارزیاب}\LTRfootnote{Evaluator Agent} و \persianfootnote{عامل منتقد/اصلاحگر}\LTRfootnote{Critic/Corrector Agent}) است. این سیستم باید قادر باشد:

\begin{enumerate}
    \item \textbf{استفاده از تولید تقویت‌شده با بازیابی:} \persianfootnote{عامل معمار}\LTRfootnote{Architect Agent} از تولید تقویت‌شده با بازیابی برای \persianfootnote{بازیابی}\LTRfootnote{retrieve} \persianfootnote{بلوک‌های ساختمانی}\LTRfootnote{building blocks} و \persianfootnote{الگوهای طراحی}\LTRfootnote{design patterns} موفق از \persianfootnote{ادبیات پژوهشی}\LTRfootnote{literature} و \persianfootnote{محک‌های}\LTRfootnote{benchmarks} \persianfootnote{جستجوی معماری عصبی}\LTRfootnote{NAS} (مانند \lr{NAS-Bench}) استفاده کند تا \persianfootnote{فضای جستجو}\LTRfootnote{search space} را به صورت \persianfootnote{آگاهانه}\LTRfootnote{informed} \persianfootnote{هرس}\LTRfootnote{prune} کند.
    \item \textbf{\persianfootnote{تولید کد قابل اعتبارسنجی}\LTRfootnote{Generating Verifiable Code}:} \persianfootnote{عامل معمار}\LTRfootnote{Architect Agent} \persianfootnote{معماری‌های}\LTRfootnote{architectures} پیشنهادی را به صورت \persianfootnote{کد}\LTRfootnote{code} اجرایی (مثلاً \lr{PyTorch} یا \lr{TensorFlow}) تولید کند.
    \item \textbf{\persianfootnote{مکانیزم خود-اصلاحی}\LTRfootnote{Self-Correction Mechanism}:} \persianfootnote{عامل ارزیاب}\LTRfootnote{Evaluator Agent} \persianfootnote{کد}\LTRfootnote{code} را اجرا کرده و \persianfootnote{نتایج}\LTRfootnote{results} \persianfootnote{کارایی}\LTRfootnote{performance} (مانند \persianfootnote{دقت}\LTRfootnote{accuracy} و \persianfootnote{تعداد پارامترها}\LTRfootnote{parameter count}) را گزارش دهد. \persianfootnote{عامل منتقد}\LTRfootnote{Critic Agent} این \persianfootnote{نتایج}\LTRfootnote{results} و \persianfootnote{خطاهای}\LTRfootnote{errors} احتمالی \persianfootnote{اجرا}\LTRfootnote{execution} را \persianfootnote{تحلیل}\LTRfootnote{analyzes} کرده و \persianfootnote{بازخورد}\LTRfootnote{feedback} \persianfootnote{سازنده}\LTRfootnote{constructive} و \persianfootnote{قابل اقدام}\LTRfootnote{actionable} (مثلاً «\persianfootnote{لایه تنگنا}\LTRfootnote{bottleneck layer} بیش از حد \persianfootnote{باریک}\LTRfootnote{narrow} است» یا «\persianfootnote{اتصال کوتاه}\LTRfootnote{skip connection} \persianfootnote{فراموش شده}\LTRfootnote{missing} است») به \persianfootnote{عامل معمار}\LTRfootnote{Architect Agent} ارائه دهد تا \persianfootnote{طراحی}\LTRfootnote{design} خود را در \persianfootnote{تکرار}\LTRfootnote{iteration} بعدی \persianfootnote{پالایش}\LTRfootnote{refine} کند.
\end{enumerate}