\pagenumbering{arabic}

\chapter{مقدمه}
\thispagestyle{empty}

\section{شرح مسأله}
فرایند ساخت و بهینه‌سازی مدل‌های یادگیری ماشین به‌طور سنتی، فرایندی پیچیده، زمان‌بر و نیازمند دانش تخصصی عمیق است. متخصصان علم داده ناچارند زمان قابل توجهی را صرف \persianfootnote{مهندسی ویژگی}\LTRfootnote{feature engineering}، \persianfootnote{انتخاب مدل}\LTRfootnote{model selection}، و \persianfootnote{تنظیم ابرپارامترها}\LTRfootnote{hyperparameter tuning} کنند. \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{Automated Machine Learning (AutoML)} با هدف خودکارسازی این \persianfootnote{خط لوله}\LTRfootnote{pipeline} و \persianfootnote{مردمی‌سازی}\LTRfootnote{democratization} یادگیری ماشین پدیدار شد. با این حال، روش‌های سنتی یادگیری ماشین خودکار، مانند \persianfootnote{بهینه‌سازی بیزی}\LTRfootnote{Bayesian optimization} یا \persianfootnote{الگوریتم‌های تکاملی}\LTRfootnote{evolutionary algorithms}، اغلب به عنوان  بهینه‌سازهای \persianfootnote{جعبه‌سیاه}\LTRfootnote{black-box} عمل می‌کنند که فاقد تفسیرپذیری بوده و در انطباق با مسائل جدید یا بهره‌برداری از دانش برون‌حوزه‌ای دچار چالش هستند.

در سال‌های اخیر، ظهور \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{Large Language Models (LLMs)} با توانایی‌های چشمگیر در \persianfootnote{درک زبان طبیعی}\LTRfootnote{Natural Language Understanding (NLU)}، استدلال و تولید کد، پارادایم جدیدی را معرفی کرده است. این مدل‌ها پتانسیل آن را دارند که از بهینه‌سازهای کور فراتر رفته و به عنوان \persianfootnote{عامل‌}\LTRfootnote{agent}های هوشمند عمل کنند. این عامل‌ها می‌توانند با استفاده از دانش پیشین خود، استدلال گام‌به‌گام، و حتی تعامل با محیط‌های اجرایی و \persianfootnote{پایگاه‌های دانش}\LTRfootnote{knowledge bases}، فرایند یادگیری ماشین خودکار را به شیوه‌ای \persianfootnote{خودمختار}\LTRfootnote{autonomous}، \persianfootnote{تطبیق‌پذیر}\LTRfootnote{adaptive} و \persianfootnote{آگاه از زمینه}\LTRfootnote{context-aware} هدایت کنند. مسئله اصلی که این سمینار به آن می‌پردازد، بررسی این تقاطع نوظهور است: چگونه می‌توان از مدل‌های زبانی بزرگ عامل-محور برای دگرگونی و ارتقای نسل بعدی سیستم‌های یادگیری ماشین خودکار بهره جست؟

\section{معرفی حوزه سمینار}
 حوزه اصلی این سمینار، یادگیری ماشین خودکار است. این حوزه به طور سنتی بر توسعه روش‌هایی برای خودکارسازی کامل خط لوله یادگیری ماشین، به‌ویژه چالش‌های محاسباتی پیچیده‌ای چون \persianfootnote{بهینه‌سازی ابرپارامترها}\LTRfootnote{Hyperparameter Optimization (HPO)} و \persianfootnote{جستجوی معماری عصبی}\LTRfootnote{Neural Architecture Search (NAS)}، تمرکز داشته است.

این سمینار یک پارادایم نوظهور و دگرگون‌ساز در این حوزه را بررسی می‌کند که مبتنی بر ادغام مدل‌های زبانی بزرگ است. برخلاف روش‌های کلاسیک یادگیری ماشین خودکار (مانند بهینه‌سازی بیزی یا الگوریتم‌های تکاملی) که اغلب به عنوان بهینه‌سازهای جعبه‌سیاه عمل می‌کنند، مدل‌های زبانی بزرگ با توانایی‌های بی‌نظیر خود در درک دستورالعمل‌های پیچیده، استدلال گام‌به‌گام و تولید کد، پتانسیل ایجاد فرایندهای بهینه‌سازی شفاف‌تر، انعطاف‌پذیرتر و آگاهانه‌تر را فراهم می‌کنند.

نکته کلیدی که این سمینار به آن می‌پردازد، بررسی این مدل‌های زبانی در چارچوب \persianfootnote{سیستم‌های عامل-محور}\LTRfootnote{Agent-based Systems} است. در این دیدگاه، مدل زبانی به عنوان مغز متفکر یک عامل هوشمند عمل می‌کند. این عامل می‌تواند به صورت خودمختار، وظایف پیچیده یادگیری ماشین خودکار را مدیریت کند، از دانش خارجی بهره ببرد، استراتژی‌های جستجو را استدلال نماید، کد اجرایی تولید کند و بر اساس بازخورد، رویکرد خود را تطبیق دهد.

بنابراین، حوزه تخصصی این سمینار، نقطه تلاقی این مفاهیم مطالعه و تحلیل \textbf{کاربرد عامل‌های هوشمند مبتنی بر مدل زبانی بزرگ} به منظور \textbf{ارتقا و تحول در نسل جدید سیستم‌های یادگیری ماشین خودکار }می‌باشد.

\section{ساختار گزارش}
این گزارش در ۴ فصل تهیه شده است. در فصل اول به بیان مقدمه و شرح مسئله پرداخته ایم. در فصل دوم مبانی و مفاهیم حوزه یادگیری ماشین خودکار، بهینه‌سازی ابرپارامترها و مدل های زبانی بزرگ عامل محور شرح داده شده است. در فصل سوم روش های مختلف از دیدگاه های عامل، دانش و نوع خروجی بررسی و مقایسه شده است. در فصل چهارم نیز به جمع‌بندی، نتیجه‌گیری از مطالب آورده شده در گزارش و کارهای آینده پرداخته‌ایم.
