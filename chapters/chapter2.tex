
\chapter{تعاریف و مفاهیم مبنایی }
\thispagestyle{empty}
\section{مقدمه}
برای درک عمیق روش‌های نوین ارائه شده در این گزارش، ضروری است که با مفاهیم و تعاریف پایه‌ای در حوزه‌های یادگیری ماشین خودکار، مدل‌های زبانی بزرگ و سیستم‌های عامل-محور آشنا شویم. این فصل به مرور این \persianfootnote{مبانی نظری}\LTRfootnote{theoretical foundations} اختصاص دارد و به عنوان سنگ بنایی برای تحلیل‌های ارائه شده در فصل سوم عمل خواهد کرد.

\section{یادگیری خودکار ماشین}
\persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{Automated Machine Learning (AutoML)} به فرایند خودکارسازی وظایف تکراری و تخصصی در طراحی و استقرار مدل‌های یادگیری ماشین اطلاق می‌شود. هدف نهایی \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML}، کاهش نیاز به دخالت متخصصان انسانی و تسریع فرایند \persianfootnote{کشف}\LTRfootnote{discovery} و \persianfootnote{اعتبارسنجی}\LTRfootnote{validation} مدل‌های کارآمد است. این فرایند معمولاً شامل مراحلی چون \persianfootnote{پیش‌پردازش داده}\LTRfootnote{data preprocessing}، \persianfootnote{مهندسی ویژگی}\LTRfootnote{feature engineering}، \persianfootnote{انتخاب مدل}\LTRfootnote{model selection} و \persianfootnote{بهینه‌سازی ابرپارامتر}\LTRfootnote{hyperparameter optimization} می‌باشد.

\subsection{بهینه‌سازی ابرپارامتر}
\persianfootnote{ابرپارامترها}\LTRfootnote{Hyperparameters} پارامترهایی در مدل یادگیری ماشین هستند که مقدار آن‌ها پیش از آغاز فرایند \persianfootnote{آموزش}\LTRfootnote{training} تنظیم می‌شود (برخلاف \persianfootnote{پارامترها}\LTRfootnote{parameters} یا \persianfootnote{وزن‌ها}\LTRfootnote{weights} که در طول آموزش یادگرفته می‌شوند). \persianfootnote{بهینه‌سازی ابرپارامتر}\LTRfootnote{Hyperparameter Optimization (HPO)} فرایند یافتن ترکیبی از ابرپارامترها است که منجر به بهترین \persianfootnote{کارایی}\LTRfootnote{performance} مدل بر روی یک \persianfootnote{مجموعه داده اعتبارسنجی}\LTRfootnote{validation dataset} می‌شود. روش‌های متداول برای این کار شامل \persianfootnote{جستجوی شبکه‌ای}\LTRfootnote{Grid Search}، \persianfootnote{جستجوی تصادفی}\LTRfootnote{Random Search} و \persianfootnote{بهینه‌سازی بیزی}\LTRfootnote{Bayesian Optimization} است. این فرایند به دلیل \persianfootnote{هزینه محاسباتی}\LTRfootnote{computational cost} بالای ارزیابی هر \persianfootnote{پیکربندی}\LTRfootnote{configuration}، بسیار چالش‌برانگیز است.

\subsection{جستجوی معماری شبکه عصبی}
\persianfootnote{جستجوی معماری عصبی}\LTRfootnote{Neural Architecture Search (NAS)} یکی از زیرشاخه‌های \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML} است که به طور خاص بر خودکارسازی طراحی \persianfootnote{معماری}\LTRfootnote{architecture} \persianfootnote{شبکه‌های عصبی عمیق}\LTRfootnote{Deep Neural Networks} تمرکز دارد. به جای تکیه بر \persianfootnote{شهود}\LTRfootnote{intuition} و \persianfootnote{طراحی دستی}\LTRfootnote{manual design} توسط متخصصان، \persianfootnote{جستجوی معماری عصبی}\LTRfootnote{NAS} از \persianfootnote{الگوریتم‌های جستجو}\LTRfootnote{search algorithms} (مانند \persianfootnote{یادگیری تقویتی}\LTRfootnote{Reinforcement Learning} یا \persianfootnote{روش‌های تکاملی}\LTRfootnote{evolutionary methods}) برای کاوش در \persianfootnote{فضای طراحی}\LTRfootnote{design space} وسیع معماری‌ها استفاده می‌کند. هدف، یافتن معماری‌ای است که بهترین \persianfootnote{توازن}\LTRfootnote{trade-off} را میان \persianfootnote{دقت}\LTRfootnote{accuracy} و \persianfootnote{کارایی محاسباتی}\LTRfootnote{computational efficiency} برقرار کند.

\section{مدل های زبانی بزرگ}
\persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{Large Language Models (LLMs)} مدل‌های \persianfootnote{زبانی}\LTRfootnote{language models} هستند که با استفاده از معماری \persianfootnote{ترنسفورمر}\LTRfootnote{Transformer} و بر روی حجم عظیمی از داده‌های متنی آموزش دیده‌اند. این مدل‌ها دارای میلیاردها پارامتر هستند و توانایی‌های شگفت‌انگیزی در \persianfootnote{درک زمینه}\LTRfootnote{understanding context}، \persianfootnote{تولید متن منسجم}\LTRfootnote{generating coherent text} و \persianfootnote{استدلال}\LTRfootnote{reasoning} از خود نشان می‌دهند.

\subsection{تاریخچه}
توسعه \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} با معرفی معماری \persianfootnote{ترنسفورمر}\LTRfootnote{Transformer} در سال ۲۰۱۷ شتاب گرفت. مدل‌هایی مانند BERT و GPT \persianfootnote{پارادایم}\LTRfootnote{paradigm} \persianfootnote{پیش‌آموزش}\LTRfootnote{pre-training} و \persianfootnote{ریزتنظیم}\LTRfootnote{fine-tuning} را تثبیت کردند. نسل‌های بعدی این مدل‌ها، با افزایش چشمگیر \persianfootnote{مقیاس}\LTRfootnote{scale} داده و پارامترها، به توانایی‌های \persianfootnote{یادگیری درون-متنی}\LTRfootnote{In-Context Learning (ICL)} دست یافتند که به آن‌ها اجازه می‌دهد وظایف جدید را بدون \persianfootnote{ریزتنظیم}\LTRfootnote{fine-tuning} و تنها با دیدن چند \persianfootnote{مثال}\LTRfootnote{example} در \persianfootnote{دستور}\LTRfootnote{prompt} انجام دهند.

\subsection{معماری}
پایه و اساس اکثر \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} مدرن، معماری \persianfootnote{ترنسفورمر}\LTRfootnote{Transformer} است که بر مکانیزم \persianfootnote{توجه خودی}\LTRfootnote{self-attention} تکیه دارد. این مکانیزم به مدل اجازه می‌دهد تا \persianfootnote{وابستگی‌های دوربرد}\LTRfootnote{long-range dependencies} را در متن مدل کند و به بخش‌های مختلف ورودی \persianfootnote{وزن‌های}\LTRfootnote{weights} متفاوتی اختصاص دهد. مدل‌ها معمولاً از \persianfootnote{پشته‌ای}\LTRfootnote{stack} از لایه‌های \persianfootnote{رمزگذار}\LTRfootnote{encoder} (مانند BERT) یا \persianfootnote{رمزگشا}\LTRfootnote{decoder} (مانند GPT) یا هر دو (مانند T5) تشکیل شده‌اند.

\subsection{کاربردها}
\persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} کاربردهای متنوعی از جمله \persianfootnote{ترجمه ماشینی}\LTRfootnote{machine translation}، \persianfootnote{خلاصه‌سازی متن}\LTRfootnote{text summarization}، \persianfootnote{پاسخ به پرسش}\LTRfootnote{question answering} و \persianfootnote{تولید محتوا}\LTRfootnote{content generation} دارند. اخیراً، توانایی آن‌ها در \persianfootnote{تولید کد}\LTRfootnote{code generation} و \persianfootnote{حل مسائل منطقی}\LTRfootnote{logical problem solving}، درهای جدیدی را برای استفاده از آن‌ها در حوزه‌های فنی‌تر مانند \persianfootnote{مهندسی نرم‌افزار}\LTRfootnote{software engineering} و \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML} گشوده است.

\subsection{تفکر و عمل}
فراتر از تولید \persianfootnote{پاسخ‌های ایستا}\LTRfootnote{static responses}، \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} می‌توانند برای \persianfootnote{تفکر}\LTRfootnote{Reasoning} و \persianfootnote{عمل}\LTRfootnote{Action} نیز به کار روند. چارچوب‌هایی مانند ReAct \cite{yao2023react} نشان دادند که چگونه یک \persianfootnote{مدل زبانی بزرگ}\LTRfootnote{LLM} می‌تواند به صورت \persianfootnote{درهم‌تنیده}\LTRfootnote{interleaved}، \persianfootnote{ردپاهای استدلالی}\LTRfootnote{reasoning traces} (تفکر) و \persianfootnote{اقدامات}\LTRfootnote{actions} (مانند جستجو در وب یا اجرای دستور) تولید کند. این قابلیت، سنگ بنای استفاده از \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} به عنوان \persianfootnote{هسته تصمیم‌گیرنده}\LTRfootnote{decision-making core} در \persianfootnote{عامل‌های خودمختار}\LTRfootnote{autonomous agents} است.

\section{عامل}
در زمینه \persianfootnote{هوش مصنوعی}\LTRfootnote{Artificial Intelligence (AI)}، \persianfootnote{عامل}\LTRfootnote{Agent} به سیستمی اطلاق می‌شود که در یک \persianfootnote{محیط}\LTRfootnote{environment} قرار دارد، آن را از طریق \persianfootnote{حسگرها}\LTRfootnote{sensors} \persianfootnote{ادراک}\LTRfootnote{perceives} می‌کند و از طریق \persianfootnote{کنشگرها}\LTRfootnote{actuators} بر آن \persianfootnote{تأثیر}\LTRfootnote{acts} می‌گذارد تا به اهداف خود دست یابد. \persianfootnote{عامل‌های زبانی}\LTRfootnote{Language Agents} نوع خاصی از عامل‌ها هستند که از \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} به عنوان \persianfootnote{موتور استدلال}\LTRfootnote{reasoning engine} اصلی خود برای \persianfootnote{پردازش ادراکات}\LTRfootnote{process perceptions} (اغلب متنی)، \persianfootnote{برنامه‌ریزی}\LTRfootnote{planning} و \persianfootnote{انتخاب اقدام}\LTRfootnote{action selection} استفاده می‌کنند.

\subsection{تک‌عاملی}
یک سیستم \persianfootnote{تک‌عاملی}\LTRfootnote{Single-Agent} شامل یک \persianfootnote{عامل}\LTRfootnote{agent} واحد است که تمام وظایف \persianfootnote{ادراک}\LTRfootnote{perception}، \persianfootnote{استدلال}\LTRfootnote{reasoning} و \persianfootnote{عمل}\LTRfootnote{action} را به تنهایی انجام می‌دهد. در زمینه \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML}، این می‌تواند یک \persianfootnote{عامل}\LTRfootnote{agent} مبتنی بر \persianfootnote{مدل زبانی بزرگ}\LTRfootnote{LLM} باشد که \persianfootnote{کل خط لوله}\LTRfootnote{entire pipeline} \persianfootnote{بهینه‌سازی}\LTRfootnote{optimization} را از ابتدا تا انتها مدیریت می‌کند.

\subsection{چندعاملی}
\persianfootnote{سیستم‌های چندعاملی}\LTRfootnote{Multi-Agent Systems (MAS)} شامل دو یا چند \persianfootnote{عامل}\LTRfootnote{agent} هستند که در یک محیط مشترک با یکدیگر \persianfootnote{تعامل}\LTRfootnote{interact} می‌کنند. این تعامل می‌تواند \persianfootnote{همکارانه}\LTRfootnote{collaborative} (برای دستیابی به یک هدف مشترک) یا \persianfootnote{رقابتی}\LTRfootnote{competitive} باشد. در \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML}، می‌توان از \persianfootnote{سیستم‌های چندعاملی}\LTRfootnote{MAS} برای \persianfootnote{تفکیک وظایف}\LTRfootnote{task decomposition} استفاده کرد؛ برای مثال، یک \persianfootnote{عامل}\LTRfootnote{agent} متخصص \persianfootnote{تحلیل داده}\LTRfootnote{data analysis}، یک \persianfootnote{عامل}\LTRfootnote{agent} متخصص \persianfootnote{تولید معماری}\LTRfootnote{architecture generation} و یک \persianfootnote{عامل}\LTRfootnote{agent} \persianfootnote{منتقد}\LTRfootnote{critic} برای ارزیابی نتایج.

\section{تولید تقویت‌شده با بازیابی}
\persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{Retrieval-Augmented Generation (RAG)} \cite{Lewis2020RAG} تکنیکی است که \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{LLMs} را با یک \persianfootnote{مکانیزم بازیابی اطلاعات}\LTRfootnote{information retrieval mechanism} خارجی ترکیب می‌کند. به جای تکیه صرف بر \persianfootnote{دانش پارامتری}\LTRfootnote{parametric knowledge} (ذخیره شده در \persianfootnote{وزن‌های}\LTRfootnote{weights} مدل)، \persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{RAG} ابتدا \persianfootnote{اطلاعات مرتبط}\LTRfootnote{relevant information} را از یک \persianfootnote{پیکره}\LTRfootnote{corpus} یا \persianfootnote{پایگاه دانش}\LTRfootnote{knowledge base} \persianfootnote{بازیابی}\LTRfootnote{retrieves} می‌کند و سپس این اطلاعات را به \persianfootnote{مدل زبانی بزرگ}\LTRfootnote{LLM} می‌دهد تا \persianfootnote{پاسخ نهایی}\LTRfootnote{final response} را بر اساس آن تولید کند. این روش به کاهش \persianfootnote{توهم}\LTRfootnote{hallucination} و افزایش \persianfootnote{دقت}\LTRfootnote{accuracy} و \persianfootnote{به‌روز بودن}\LTRfootnote{up-to-dateness} اطلاعات کمک می‌کند \cite{xia2025ragselfreasoning}.

\subsection{پایگاه دانش}
\persianfootnote{پایگاه دانش}\LTRfootnote{Knowledge Base} در \persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{RAG} معمولاً مجموعه‌ای از \persianfootnote{اسناد}\LTRfootnote{documents} (مانند مقالات پژوهشی، مستندات فنی، یا نتایج آزمایش‌های قبلی) است. این اسناد اغلب به \persianfootnote{قطعات}\LTRfootnote{chunks} کوچکتر تقسیم شده و به صورت \persianfootnote{نمایش‌های برداری}\LTRfootnote{vector representations} (یا \persianfootnote{نهفتگی‌ها}\LTRfootnote{embeddings}) در یک \persianfootnote{پایگاه داده برداری}\LTRfootnote{vector database} ذخیره می‌شوند تا \persianfootnote{بازیابی مبتنی بر شباهت معنایی}\LTRfootnote{semantic similarity retrieval} به سرعت انجام شود.

\subsection{ترکیب با عامل}
\persianfootnote{عامل‌های هوشمند}\LTRfootnote{Intelligent agents} می‌توانند از \persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{RAG} به عنوان یک \persianfootnote{ابزار}\LTRfootnote{tool} کلیدی استفاده کنند. زمانی که یک \persianfootnote{عامل}\LTRfootnote{agent} \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{AutoML} با یک \persianfootnote{مجموعه داده}\LTRfootnote{dataset} جدید روبرو می‌شود، می‌تواند از \persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{RAG} برای جستجو در \persianfootnote{پایگاه دانش}\LTRfootnote{knowledge base} (شامل مقالات، \persianfootnote{فراداده‌های}\LTRfootnote{metadata} \persianfootnote{مجموعه داده‌های}\LTRfootnote{datasets} مشابه، و نتایج \persianfootnote{بهینه‌سازی‌های}\LTRfootnote{optimizations} گذشته) استفاده کند. این \persianfootnote{دانش بازیابی‌شده}\LTRfootnote{retrieved knowledge} به \persianfootnote{عامل}\LTRfootnote{agent} کمک می‌کند تا \persianfootnote{تصمیمات آگاهانه‌تری}\LTRfootnote{more informed decisions} در مورد \persianfootnote{فضای جستجوی}\LTRfootnote{search space} \persianfootnote{ابرپارامترها}\LTRfootnote{hyperparameters} یا \persianfootnote{بلوک‌های معماری}\LTRfootnote{architectural blocks} اتخاذ کند \cite{singh2025agenticrag}.

