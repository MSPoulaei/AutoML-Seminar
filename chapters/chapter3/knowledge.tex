\section[تحلیل منابع دانش]{\persianfootnote{تحلیل منابع دانش}\LTRfootnote{Knowledge Source Analysis}}

کارآمدی سامانه‌های خودکارسازی یادگیری ماشین مبتنی بر مدل‌های زبانی بزرگ به‌صورت بنیادین به چگونگی اکتساب، مدیریت و بهره‌برداری از دانش در سراسر فرایند \persianfootnote{بهینه‌سازی}\LTRfootnote{optimization} وابسته است. رویکردهای معاصر طیفی از راهبردهای \persianfootnote{تقویت دانش}\LTRfootnote{knowledge augmentation} را پوشش می‌دهند؛ از \persianfootnote{یادگیری درون‌متنی}\LTRfootnote{In-Context Learning} صرف تا چارچوب‌های \persianfootnote{تولید تقویت‌شده با بازیابی}\LTRfootnote{Retrieval-Augmented Generation (RAG)} که هر یک پیامدهای متمایزی برای کارایی \persianfootnote{جست‌وجو}\LTRfootnote{search} و \persianfootnote{تعمیم‌پذیری}\LTRfootnote{generalization} دارند.

\subsection[دانش درونی: تاریخچهٔ آزمون و بازتاب]{\persianfootnote{دانش درونی: تاریخچهٔ آزمون و بازتاب}\LTRfootnote{System-Internal Knowledge: Trials and Reflection}}
این رسته، دانشِ تولیدشده توسط خود سامانه را در بر می‌گیرد—از اتکای مستقیم به تاریخچهٔ آزمون‌ها در پنجرهٔ \persianfootnote{زمینه}\LTRfootnote{context window} تا حافظهٔ رویدادی و \persianfootnote{خودبازتابی}\LTRfootnote{self-reflection} که به‌تدریج به \persianfootnote{بازخوردِ قابلِ اقدام}\LTRfootnote{actionable feedback} و اصول طراحی تقطیر می‌شوند.
\subsubsection{\persianfootnote{یادگیری درون‌متنی از تاریخچهٔ بهینه‌سازی}\protect\LTRfootnote{In-Context Learning from Optimization History}}

یک راهبرد رایج، پنجرهٔ \persianfootnote{زمینه}\LTRfootnote{context window} مدل را همچون مخزن اصلی دانش در نظر می‌گیرد و صرفاً بر تاریخچهٔ آزمون‌های انباشته‌شده طی فرایند \persianfootnote{بهینه‌سازی}\LTRfootnote{optimization} تکیه می‌کند. سامانه‌های مبتنی بر این ایده، پیکربندی‌های پیشین و سنجه‌های کارایی متناظر را در دستور می‌گنجانند تا مدل بتواند از رهگذر بازخورد تکرارشونده پیشنهادها را پالایش کند \cite{zhang2023usingLLMforHPO, zheng2023GENIUS, liu2024LLAMBO}. این تاریخچه ممکن است به قالب‌های گوناگونی \persianfootnote{سریال‌سازی}\LTRfootnote{serialization} شود: گفت‌وگوهای \persianfootnote{سبک‌گپ}\LTRfootnote{chat-style dialogues} که توالی زمانی تعاملات را حفظ می‌کنند، \persianfootnote{خلاصه‌های فشرده}\LTRfootnote{compressed summaries} برای مهار قیود طول زمینه، \persianfootnote{الگوهای اندک‌نمونه}\LTRfootnote{few-shot demonstrations} برگزیده از جمعیت ارزیابی‌شده \cite{zhang2023usingLLMforHPO, chen2023Evoprompting}، و نیز \persianfootnote{تجربه‌های تاریخیِ استانداردسازی‌شده}\LTRfootnote{canonicalized historical experiences} که داده‌های ناهمگنِ گذشته (پیکربندی‌های \lr{JSON}، پیاده‌سازی‌های کد، سنجه‌های عددی) را به نمایش‌های یکنواختِ زبان طبیعی تبدیل می‌کنند تا پردازش و قیاس توسط مدل تسهیل شود \cite{zhang-etal-2024-MLCopilot}.

در این رویکردِ تکمیلی، ابرپارامترهای عددی برای بهبود استدلال \persianfootnote{گسسته‌سازی}\LTRfootnote{discretized} می‌شوند (مثلاً به سطوح «کم»، «متوسط»، «زیاد»)، و تجربه‌های استانداردسازی‌شده با \persianfootnote{نهفتارسازی}\LTRfootnote{embedding} و نمایه‌سازی در پایگاهِ برداری پشتیبانی می‌شوند تا \persianfootnote{بازیابی مبتنی بر شباهت}\LTRfootnote{similarity-based retrieval}، \persianfootnote{برترین‌های k}\LTRfootnote{top-k} نمونهٔ مرتبط را برای نمایش درون‌متنی برگزیند. فراتر از درجِ خامِ تجربه‌ها، \persianfootnote{استخراج دانش برون‌خط}\LTRfootnote{offline knowledge elicitation} از طریق خلاصه‌سازیِ تکرارشوندهٔ مبتنی بر مدل و \persianfootnote{اعتبارسنجیِ پسین}\LTRfootnote{post-validation} روی وظایف کنارگذاشته، اصول طراحیِ سطح‌بالا و \persianfootnote{بازخوردِ قابلِ اقدام}\LTRfootnote{actionable feedback} را تقطیر می‌کند؛ این دانشِ استخراج‌شده می‌تواند به‌صورت راهنمای سامانه یا الگوهای اندک‌نمونه در متن تزریق شود و حتی \persianfootnote{تولید راه‌حل تک‌نمونه‌ای}\LTRfootnote{one-shot solution generation} برای وظایف نو را میسر سازد \cite{zhang-etal-2024-MLCopilot}.

این پارادایم به‌ویژه در سناریوهای کم‌بودجه مؤثر است؛ جایی که پیشین‌های یادگرفته‌شدهٔ مدل و تجربه‌های استانداردسازی‌شده می‌توانند بدون دادهٔ تجربی فراوان مسیر اکتشاف را هدایت کنند. در بسترهای \persianfootnote{بهینه‌سازی بیزی}\LTRfootnote{Bayesian optimization}، مشاهدات تاریخی، آغازِ گرم، \persianfootnote{نمونه‌برداری نامزد}\LTRfootnote{candidate sampling} و \persianfootnote{مدلسازی جانشین}\LTRfootnote{surrogate modeling} را به‌طور کامل از راه \persianfootnote{سریال‌سازی زبان طبیعی}\LTRfootnote{natural language serialization} ارزیابی‌های پیشین شرطی‌سازی می‌کنند؛ و در حالی‌که در حالت‌های \persianfootnote{بی‌نمونه}\LTRfootnote{zero-shot} یا \persianfootnote{کم‌نمونه}\LTRfootnote{few-shot} عمل می‌کنند، کارایی رقابتی در قیاس با روش‌های سنتی نشان می‌دهند \cite{liu2024LLAMBO}. تجربه‌های استانداردسازی‌شده با فراهم‌سازی نمونه‌های مشابهِ تأییدشده و قواعد طراحیِ تقطیرشده، می‌توانند این مراحل را دقیق‌تر \persianfootnote{گرم‌آغاز}\LTRfootnote{warmstart} کنند و میدان جست‌وجو را به‌صورت هدایت‌شده منقبض سازند \cite{zhang-etal-2024-MLCopilot}.

محدودیت اصلی در بهینه‌سازی‌های \persianfootnote{بلندافق}\LTRfootnote{long-horizon} رخ می‌نماید؛ جایی‌که قیود پنجرهٔ زمینه مستلزم نگهداشت گزینشی یا \persianfootnote{فشرده‌سازی ازدست‌ده}\LTRfootnote{lossy compression} تاریخچه است و چه‌بسا الگوهای حیاتی برای پالایشِ مرحلهٔ پایانی را حذف کند. \persianfootnote{استانداردسازی}\LTRfootnote{canonicalization} تا حدی این معضل را با خلاصه‌های ساخت‌یافتهٔ متراکم و بازیابی هدفمندِ \lr{top-k} تخفیف می‌دهد، اما همچنان با برش اطلاعاتی، سوگیری‌های ناشی از گسسته‌سازی، و حساسیت به \persianfootnote{امتیازدهیِ ربط}\LTRfootnote{relevance scoring} و پوشش مخزن مواجه است. با این‌همه، چون مصرف نهاییِ این دانش درونِ همان پنجرهٔ زمینه صورت می‌گیرد، مرز میان «دانش درون‌متنیِ صرف» و «تقویتِ مبتنی بر بازیابی» کم‌رنگ‌تر می‌شود؛ و ادغامِ تاریخچهٔ آزمون با تجربه‌های استانداردسازی‌شده، پایایی و کاراییِ یادگیری درون‌متنی را در عمل ارتقا می‌دهد \cite{zhang2023usingLLMforHPO, zheng2023GENIUS, chen2023Evoprompting, liu2024LLAMBO, zhang-etal-2024-MLCopilot}.

% \subsubsection{\persianfootnote{حافظهٔ رویدادی از رهگذر درخت‌های تغییر}\protect\LTRfootnote{Episodic Memory via Modification Trees}}

% در بسترهای تکاملیِ \persianfootnote{جست‌وجوی معماری عصبی}\LTRfootnote{Neural Architecture Search (NAS)}، برخی چارچوب‌ها \persianfootnote{درخت‌های تغییرِ شبکه}\LTRfootnote{network modification trees} را نگه می‌دارند که کل مسیر دگرگونی‌های معماری—از روابط والد-فرزند و دگرگونی‌های اعمال‌شده تا سنجه‌های کارایی حاصل—را بایگانی می‌کنند \cite{Yang2025NADER}. این حافظهٔ رویدادی، راهبردهای کاوشِ \persianfootnote{عمق‌نخست}\LTRfootnote{depth-first} و \persianfootnote{عرض‌نخست}\LTRfootnote{breadth-first} را پشتیبانی می‌کند؛ و سازوکارهای بازیابی با جست‌وجوی شباهت، تغییرات مشابهِ گذشته را می‌یابند. در ترکیب با \persianfootnote{کارگزارِ بازتابنده}\LTRfootnote{reflector agent} که الگوهای خطای مکرر و راهبردهای موفقِ طراحی را از سوابق استخراج می‌کند، سامانه بی‌نیاز از دادهٔ آموزشی بیرونی، به‌تدریج سرانگشتانِ حوزه‌ویژه می‌پرورد.

% \subsubsection{\persianfootnote{بایگانی‌های کیفیت-تنوع به‌منزلهٔ حافظه}\protect\LTRfootnote{Quality-Diversity Archives as Memory}}

% در چارچوب‌هایی که مدل‌های زبانی را با \persianfootnote{بهینه‌سازیِ کیفیت-تنوع}\LTRfootnote{quality-diversity optimization} ادغام می‌کنند، دو بایگانی به‌منزلهٔ حافظهٔ بلندمدت عمل می‌کنند: یکی برای نگهداری معماری‌های برگزیدهٔ شبکه با \persianfootnote{توصیفگرهای رفتاری}\LTRfootnote{behavioral descriptors} (مانند نسبت پهنا-به-عمق، و \persianfootnote{تعداد عملیات ممیز شناور}\LTRfootnote{FLOPs})؛ و دیگری برای بایگانیِ راهنماهای متنی با \persianfootnote{دما}\LTRfootnote{temperature}ها و \persianfootnote{نمراتِ کنجکاوی}\LTRfootnote{curiosity scores} متناظر \cite{LLMatic2024}. پیگیریِ مشترکِ سنجه‌های \persianfootnote{برازش}\LTRfootnote{fitness} و \persianfootnote{بداعت}\LTRfootnote{novelty} در نسل‌های پیاپی، تعادلی میان بهره‌برداری از برترین‌های شناخته‌شده و اکتشاف نواحی کم‌نمونه‌برداری‌شده برقرار می‌کند؛ و دانش ازپیش‌آموختهٔ مدل دربارهٔ \persianfootnote{پیکره‌های کد}\LTRfootnote{code corpora}، فرایند جهش را به‌طور ضمنی—حتی بدون بازیابی صریح—تقویت می‌کند.

\subsection[دانش بیرونی: بازیابی از ادبیات و مخازن]{\persianfootnote{دانش بیرونی: بازیابی از ادبیات و مخازن}\LTRfootnote{External Knowledge via Retrieval}}

سامانه‌های پیشرفته‌تر، تولید تقویت‌شده با بازیابی را برای ادغام دانش بیرون از مسیر بهینه‌سازی به کار می‌گیرند. این چارچوب‌ها مخازن دانش ساخت‌یافته—عموماً \persianfootnote{پایگاه‌های دادهٔ برداری}\LTRfootnote{vector databases} نمایه‌شده با \persianfootnote{نهفتارها}\LTRfootnote{embeddings}—نگه می‌دارند تا بر پایهٔ زمینهٔ وظیفهٔ جاری، اطلاعات مرتبط را بازیابی کرده و در راهنماهای متنی تزریق کنند و بدین‌سان تصمیم‌سازی را اطلاع‌رسانی کنند.

\subsubsection{\persianfootnote{استخراج دانش مبتنی بر ادبیات پژوهشی}\protect\LTRfootnote{Literature-Driven Knowledge Extraction}}

چند رویکرد، دانش راهبردی را از ادبیات علمی برای هدایت تصمیم‌های معماری گردآوری می‌کنند. یک راهبرد از \persianfootnote{کارگزاران خوانشِ تخصصی}\LTRfootnote{specialized reader agents} بهره می‌برد که مقالات اخیر را \persianfootnote{خزش}\LTRfootnote{crawl} کرده، نکته‌های روش‌شناختی را از چکیده‌ها و بخش‌های روش استخراج می‌کنند و در پایگاه‌های دادهٔ برداری برای \persianfootnote{بازیابی مبتنی بر شباهت}\LTRfootnote{similarity-based retrieval} بایگانی می‌نمایند \cite{Yang2025NADER}. در خلال بهینه‌سازی، \persianfootnote{پیشنهادهای تغییر}\LTRfootnote{modification proposals} به‌منزلهٔ پرسش، اصول طراحی مرتبط را فراخوانی می‌کنند؛ و بدین‌ترتیب سامانه بدون آن‌که مدل پایه الزاماً بر تازه‌ترین انتشارات آموزش دیده باشد، از مرز دانش روز بهره می‌گیرد. نمونه‌ای دیگر، خلاصه‌هایی از مقالات arXiv و جست‌وجوهای وب را از طریق \persianfootnote{رابط‌های برنامه‌نویسی کاربردی}\LTRfootnote{APIs} بازیابی کرده و راهنماهای برنامه‌ریزی را با بینش‌های بیرونی پیرامون مدل‌ها، ابرپارامترها و داده‌مجموعه‌ها غنی می‌کند تا تنوع و سازگاری طرح را ارتقا دهد \cite{trirat2025automlagent}.

این استخراج دانش، برای \persianfootnote{طراحی معماری‌های عصبی}\LTRfootnote{neural architecture design} بس سودمند است؛ چراکه نوآوری‌های اخیر در \persianfootnote{ترکیب لایه‌ها}\LTRfootnote{layer compositions}، \persianfootnote{اتصالات پرشی}\LTRfootnote{skip connections} یا \persianfootnote{طرحواره‌های نرمال‌سازی}\LTRfootnote{normalization schemes} چه‌بسا در \persianfootnote{پارامترهای منجمد}\LTRfootnote{frozen parameters} مدل بازتاب نیافته باشند. با این‌همه، کیفیت دانش بازیابی‌شده به‌نحو حساس به سازوکار \persianfootnote{امتیازدهیِ ربط}\LTRfootnote{relevance scoring} و پوشش پیکرهٔ ادبیات نمایه‌شده وابسته است.

\subsubsection{\persianfootnote{مخازن داده‌مجموعه و مدل}\protect\LTRfootnote{Dataset and Model Repositories}}

در کنار بازیابی مبتنی بر ادبیات، چند سامانه از مخازن بیرونی برای فراداده‌های داده‌مجموعه‌ها و مدل‌های ازپیش‌آموزش‌دیده پرس‌وجو می‌کنند. چارچوب‌هایی که کل زنجیرهٔ \persianfootnote{خودکارسازی یادگیری ماشین}\LTRfootnote{AutoML} را راهبری می‌کنند، \persianfootnote{کارت‌های داده‌مجموعه}\LTRfootnote{dataset cards} از پلتفرم‌هایی مانند \lr{Kaggle} و \persianfootnote{کارت‌های مدل}\LTRfootnote{model cards} از \lr{HuggingFace} را بازیابی کرده و فرادادهٔ ساخت‌یافته—از جمله \persianfootnote{وجه‌های داده}\LTRfootnote{modalities}، متغیرهای هدف، معماری‌های مدل و \persianfootnote{بازه‌های ابرپارامتر}\LTRfootnote{hyperparameter ranges}—را در راهنماهای متنی می‌گنجانند تا تصمیم‌های پایین‌دستی را غنی کنند \cite{trirat2025automlagent, shen2023HuggingGPT}. برای داده‌مجموعه‌های نادیده، سازوکارهای \persianfootnote{انتقال مبتنی بر شباهت}\LTRfootnote{similarity-based transfer} با محاسبهٔ همبستگی میان \persianfootnote{کدگذاریِ کارت‌های داده}\LTRfootnote{data card encodings} (با مدل‌هایی مانند \lr{CLIP}) مسائل مشابه را شناسایی کرده و ابرپارامترها یا الگوهای معماری را از تجربه‌های تاریخی منتقل می‌سازند \cite{zhang2023AutomlGPTAutomaticMachineLearning}.

این \persianfootnote{تقویتِ مبتنی بر فراداده}\LTRfootnote{metadata-driven augmentation} تعمیم‌پذیری میان حوزه‌های گوناگون را بدون نیاز به آموزش‌های خاصِ وظیفه ممکن می‌کند؛ هرچند به دسترس‌پذیری مخازن خوش‌سامان و برچسب‌گذاری دقیق فراداده متکی است.

\subsection[راهبردهای تقویتِ آمیخته]{\persianfootnote{راهبردهای تقویتِ آمیخته}\LTRfootnote{Hybrid Augmentation Strategies}}

سامانه‌های پیشرفتهٔ روز، غالباً چند منبع دانش را برای بهره‌گیری از قوت‌های مکمل با هم ترکیب می‌کنند. چارچوب‌های \persianfootnote{چندکارگزاره}\LTRfootnote{multi-agent frameworks} ممکن است \persianfootnote{برنامه‌ریزیِ تقویت‌شده با بازیابی}\LTRfootnote{retrieval-augmented planning}—که دانش ادبیات و مخازن را برای راهبردهای سطح‌بالا به کار می‌گیرد—را با \persianfootnote{حافظهٔ رویدادی}\LTRfootnote{episodic memory} برآمده از گزارش‌های تجربی که اجرای عملی را صیقل می‌دهد، جفت کنند \cite{trirat2025automlagent, Yang2025NADER}. به‌همین سیاق، تاریخچهٔ آزمونِ درون‌متنی می‌تواند با تجربه‌های استانداردسازی‌شدهٔ بازیابی‌شده غنی شود تا \persianfootnote{گرم‌آغاز}\LTRfootnote{warmstart} بهینه‌سازی را—به‌ویژه در مواجهه با وظایف نو با ارزیابی‌های اولیهٔ محدود—تسریع کند \cite{zhang-etal-2024-MLCopilot}.

گزینش معماریِ تقویت دانش، به‌طرزِ حساس با پارادایم عملیاتی کارگزار برهم‌کنش دارد: \persianfootnote{پرومپت‌دهیِ تکرارشونده}\LTRfootnote{iterative prompting} بیشترین سود را از \persianfootnote{خلاصه‌های فشردهٔ تاریخی}\LTRfootnote{compressed historical summaries} می‌برد؛ \persianfootnote{عملگرهای تکاملی}\LTRfootnote{evolutionary operators} برای نگهداشت تنوع به بایگانی‌های کیفیت-تنوع اتکا دارند؛ و \persianfootnote{کنترل‌گرهای جریان‌کار}\LTRfootnote{workflow controllers} برای هماهنگ‌سازی مراحل ناهمگونِ خط لوله، به فرادادهٔ ساخت‌یافته نیازمندند. با گسترش ظرفیت‌های پنجرهٔ زمینه و پختگیِ سازوکارهای بازیابی، مرز میان دانش درون‌متنی و بیرونی هرچه بیشتر محو می‌شود و ادغامی غنی‌تر از پیشین‌های آموخته، شواهد تجربی و خبرگیِ حوزه را امکان‌پذیر می‌سازد.