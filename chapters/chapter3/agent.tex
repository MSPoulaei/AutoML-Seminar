
\section{تحلیل بر مبنای معماری عامل}
\subsection{سامانه‌های تک‌عاملی}

بیشینهٔ سامانه‌های مبتنی بر مدل‌های زبانی بزرگ برای خودکارسازی یادگیری ماشین، معماری‌های تک‌عاملی را برمی‌گزینند که در آن یک عامل منفرد کل جریان بهینه‌سازی را مدیریت می‌کند. بر مبنای چگونگی ادغام مدل زبانی در فرایند بهینه‌سازی، این سامانه‌ها در چند پارادایم عملیاتی متمایز قرار می‌گیرند.

\subsubsection{\persianfootnote{بهینه‌سازی مستقیم از طریق دستوردهی تکراری}\protect\LTRfootnote{Direct Optimization through Iterative Prompting}}
در این رویکرد برجسته، مدل‌های زبانی به‌منزلهٔ بهینه‌سازهای \persianfootnote{جعبه‌سیاه}\LTRfootnote{black-box} به‌کار می‌روند که پیکربندی‌ها را پیشنهاد می‌کنند و از راه \persianfootnote{حلقه‌های بازخورد}\LTRfootnote{feedback loops} آن‌ها را پالایش می‌کنند. مدل با تکیه بر تاریخچهٔ \persianfootnote{آزمون‌ها}\LTRfootnote{trial} که به‌صورت \persianfootnote{گفت‌وگوهای چت}\LTRfootnote{chat-style dialogues} یا خلاصه‌های فشرده انباشته می‌شود، \persianfootnote{زمینه}\LTRfootnote{context} را حفظ می‌کند و پالایش تکراری مبتنی بر معیارهای اعتبارسنجی را ممکن می‌سازد \cite{zhang2023usingLLMforHPO, zheng2023GENIUS}. این پارادایم به چارچوب‌های بهینه‌سازی \persianfootnote{بیزی}\LTRfootnote{Bayesian} نیز بسط یافته است؛ جایی که مدل‌های آغاز گرم، نمونه‌گیری از نامزدها و \persianfootnote{مدل‌سازی جانشین}\LTRfootnote{surrogate modeling} را با اتکاء به استدلال زبان طبیعی و مشروط بر تاریخچهٔ بهینه‌سازی انجام می‌دهند \cite{liu2024LLAMBO}. این رویکردها در تنظیمات با بودجه کم کارایی رقابتی نشان می‌دهند و بی‌آن‌که به \persianfootnote{ریزتنظیم}\LTRfootnote{fine-tuning} نیاز داشته باشند، بر \persianfootnote{یادگیری زمینه ای}\LTRfootnote{in-context learning} از توصیف مسئله و بازخورد تجربی تکیه می‌کنند.

\subsubsection{\persianfootnote{عملگرهای تکاملی}\protect\LTRfootnote{Evolutionary Operators}}
راهبردی دیگر، مدل زبانی را به‌عنوان عملگرهای \persianfootnote{جهش}\LTRfootnote{mutation} یا \persianfootnote{ترکیب}\LTRfootnote{crossover} درون چارچوب‌های \persianfootnote{تکاملی}\LTRfootnote{evolutionary} جا می‌دهد. به‌جای جایگزینی الگوریتم‌های جست‌وجوی سنتی، این سامانه‌ها آن‌ها را با تنوع‌های تولیدشده توسط مدل زبانی تقویت می‌کنند. مدل می‌تواند تغییرات معماری مبتنی بر کد را در چارچوب‌های \persianfootnote{کیفیت–تنوع}\LTRfootnote{quality-diversity} بسازد \cite{LLMatic2024} یا به‌صورت عملگرهای \persianfootnote{تطبیقی}\LTRfootnote{adaptive operators} که میان نسل‌ها با \persianfootnote{تنظیم دستور}\LTRfootnote{prompt-tuning} پالایش می‌شوند عمل کند \cite{chen2023Evoprompting}. برخی پیاده‌سازی‌ها \persianfootnote{توانایی‌های بازتابی}\LTRfootnote{reflective capabilities} را نیز می‌گنجانند؛ به این معنا که مدل پیامدهای جهش را تحلیل می‌کند و \persianfootnote{بازخورد زبانی}\LTRfootnote{linguistic feedback} برای هدایت تکرارهای بعدی تولید می‌کند \cite{ji2025RZNAS}. این ادغام، \persianfootnote{پایداری}\LTRfootnote{robustness} جست‌وجوی تکاملی را حفظ می‌کند و در عین حال از \persianfootnote{خلاقیت}\LTRfootnote{creativity} مدل در تولید تنوع‌های معنادار بهره می‌گیرد. نمونه‌ای شاخص، GPT-NAS است که در آن \persianfootnote{مدل زبانی}\LTRfootnote{GPT} به‌منزلهٔ یک \persianfootnote{بازساز}\LTRfootnote{reconstructor} معماری عمل کرده و با ماسک‌گذاری و بازتولید لایه‌ها، نامزدهای نمونه‌برداری‌شده توسط \persianfootnote{الگوریتم ژنتیک}\LTRfootnote{genetic algorithm} را بهبود می‌دهد؛ بنابراین عملاً نقشی هم‌ارز با یک عملگر جهشِ آگاه از زمینه ایفا می‌کند بی‌آن‌که راهبرد جست‌وجوی تکاملی را جایگزین کند \cite{Yu2025GPTNAS}.

\subsubsection{\persianfootnote{کنترل‌گرهای جریان کار}\protect\LTRfootnote{Workflow Controllers}}
در این پارادایم، مدل‌های زبانی به‌مثابه \persianfootnote{هماهنگ‌کننده}\LTRfootnote{orchestrator} برای مدیریت اجزای \persianfootnote{خطّ لوله}\LTRfootnote{pipeline} به کار می‌روند. سامانه با ترکیب دستور‌هایی که \persianfootnote{فرادادهٔ ساختاریافته}\LTRfootnote{structured metadata}-از جمله \persianfootnote{کارت‌های داده}\LTRfootnote{data cards} و \persianfootnote{کارت‌های مدل}\LTRfootnote{model cards}-را در خود دارند، مدل را در مراحل پیاپی از پردازش داده، انتخاب مدل تا تنظیم فراپارامتر هدایت می‌کند \cite{zhang2023AutomlGPTAutomaticMachineLearning, shen2023HuggingGPT}. برخی پیاده‌سازی‌ها برنامه‌های پیچیدهٔ یادگیری ماشین را به \persianfootnote{مولفه‌های ماژولار}\LTRfootnote{modular components} تجزیه می‌کنند که به‌طور جداگانه تولید و با \persianfootnote{آزمون‌های واحد خودکار}\LTRfootnote{automated unit tests} راستی‌آزمایی می‌شوند تا سازگاری تضمین گردد \cite{xu2024largeTextToML}. این رویکرد با شکستن خطوط لولهٔ طولانی و ناهمگون به زیروظایف قابل مدیریت و اتکاء به \persianfootnote{دستوردهی زمینه‌مند}\LTRfootnote{contextual prompting}، انسجام کلّی را حفظ می‌کند.
\subsection{سامانه‌های چندعاملی}

معماری‌های چندعاملی با تفکیک نقش، زیروظایف یادگیری ماشین خودکار را میان عامل‌هایی با قابلیت‌های مکمل توزیع می‌کنند. این سامانه‌ها از \persianfootnote{رهگذر تفکیک کارکردی}\LTRfootnote{functional decomposition} و \persianfootnote{همکاری بین‌عاملی}\LTRfootnote{inter-agent collaboration}، مدیریت پیچیدگی و استدلال پیچیده‌تر را ممکن می‌سازند.

\subsubsection{\persianfootnote{همکاری مبتنی بر نقش}\protect\LTRfootnote{Role-Based Collaboration}}
الگوی پایه، دو عامل تخصصی با مسئولیت‌های متمایز را به‌کار می‌گیرد. در یک ساختار، تولید \persianfootnote{پیکربندی}\LTRfootnote{configuration} از اجرای تجربی جدا می‌شود: عامل سازنده نیازمندی‌ها را تفسیر و پیکربندی‌های پیشنهادی همراه با استدلال ارائه می‌کند و عامل اجراکننده آموزش را انجام داده و نتایج را در گزارش‌های مشترک می‌گنجاند تا چرخه‌های بعدی پیشنهادهای سازنده را تغذیه کند \cite{liu2025agenthpo}. این تقسیم کار بازتاب گردش‌کار متخصصان است و با \persianfootnote{حافظهٔ ترتیبی}\LTRfootnote{episodic memory} انباشته، به عملکرد خودگردان بدون مداخلهٔ انسانی می‌انجامد. افزون بر این، همین الگو را می‌توان به سطح تیمی تعمیم داد: نمونهٔ پیشرفته، تقسیم عامل‌ها به \persianfootnote{تیم پژوهش}\LTRfootnote{Research Team} و \persianfootnote{تیم توسعه}\LTRfootnote{Development Team} است که به‌ترتیب دانش را از \persianfootnote{ادبیات پژوهشی}\LTRfootnote{literature} استخراج و پیشنهادهای تغییر را می‌سازند، و آن پیشنهادها را بر \persianfootnote{نمایش‌های گراف}\LTRfootnote{graph representations} اعمال کرده و هم بازخورد فوری و هم استخراج تجربهٔ بلندمدت فراهم می‌کنند \cite{Yang2025NADER}. در این قالب، \persianfootnote{پایگاه‌های دادهٔ برداری}\LTRfootnote{vector databases} با \persianfootnote{بازیابی مبتنی بر شباهت}\LTRfootnote{similarity-based retrieval} برای آمیختن دانش ادبیات با سوابق طراحی به‌کار می‌روند تا چرخه‌های بعدی پیشنهاددهی و اجرا بهتر هدایت شوند.

\subsubsection{\persianfootnote{هماهنگی سلسله‌مراتبی}\protect\LTRfootnote{Hierarchical Coordination}}
در ساختارهای پیچیده‌تر، چند عامل تخصصی تحت نظارت یک \persianfootnote{مدیر عامل}\LTRfootnote{Agent Manager} سازمان می‌یابند. مدیر با \persianfootnote{استدلال تقویت‌شده با بازیابی}\LTRfootnote{retrieval-augmented reasoning} طرح‌های متنوعی می‌سازد، آن‌ها را به زیروظایف \persianfootnote{قابل موازی‌سازی}\LTRfootnote{parallelizable subtasks} واگشایی و به عامل مناسب تخصیص می‌دهد و از رهگذر راستی‌آزمایی چندمرحله‌ای و \persianfootnote{حلقه‌های بازنگری}\LTRfootnote{revision loops} نتایج را اعتبارسنجی می‌کند \cite{trirat2025automlagent}. حتی در نبود یک مدیر صریح، تیم‌بندی کارکردیِ یادشده معمولاً با \persianfootnote{پروتکل‌های هماهنگی ساختاریافته}\LTRfootnote{structured coordination protocols} اداره می‌شود: اکتشاف معماری روی یک \persianfootnote{درخت تغییرات شبکه}\LTRfootnote{network modification tree} با راهبردهای پیمایش عمیق/سطحی، تخصیص زیروظایف به عامل مناسب، و اعتبارسنجی چندمرحله‌ای از طریق تبدیل گراف به کد و سنجش ایزومرفی و اجرایی‌بودن؛ سپس حلقه‌های بازنگری با تحلیل خطاها و بازیابی تجربه‌های مشابه از حافظهٔ برداری، از تکرار خطاها جلوگیری می‌کند \cite{Yang2025NADER}. این معماری کلّ خط لولهٔ AutoML را از بازیابی داده تا \persianfootnote{استقرار}\LTRfootnote{deployment} به‌صورت کارآمد پیش می‌برد و \persianfootnote{وابستگی‌های بین‌گامی}\LTRfootnote{inter-step dependencies} را مدیریت می‌کند.

پارادایم چندعاملی با افزودن پیچیدگی هماهنگی، در برابر \persianfootnote{توضیح‌پذیری}\LTRfootnote{interpretability} بهبود‌یافته از طریق تفکیک صریح نقش‌ها و کارایی بهتر بهینه‌سازی از رهگذر استدلال تخصصی معامله می‌کند؛ هرچند به مدیریت حافظهٔ پیشرفته برای حفظ سازگاری در تعاملات عامل‌ها و طراحی دقیق پروتکل‌های ارتباطی برای جلوگیری از شکست‌های هماهنگی نیاز دارد. تجربهٔ ساختارهایی نظیر NADER نشان می‌دهد حافظهٔ تجربه‌ای مبتنی بر بازیابی می‌تواند نرخ خطاهای تکراری را کاهش داده و کیفیت اکتشاف را بهبود بخشد \cite{Yang2025NADER}.