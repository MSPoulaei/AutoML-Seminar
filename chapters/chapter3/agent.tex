\section{طبقه‌بندی بر اساس معماری عامل}
در چشم‌انداز رو‌به‌تحول رویکردهای مبتنی بر \persianfootnote{مدل‌های زبانی بزرگ}\LTRfootnote{Large Language Models (LLMs)} برای \persianfootnote{یادگیری ماشین خودکار}\LTRfootnote{Automated Machine Learning (AutoML)}، \persianfootnote{جست‌وجوی معماری شبکه‌های عصبی}\LTRfootnote{Neural Architecture Search (NAS)} و \persianfootnote{بهینه‌سازی ابرپارامتر}\LTRfootnote{Hyperparameter Optimization (HPO)}، یک تمایز بنیادین در \persianfootnote{معماری عامل}\LTRfootnote{Agent Architecture} برجسته است: \persianfootnote{تک‌عاملی}\LTRfootnote{Single-Agent} در برابر \persianfootnote{چندعاملی}\LTRfootnote{Multi-Agent}. این طبقه‌بندی بازتاب‌دهنده نحوه سازمان‌دهی و ارکستراسیون مدل‌های زبانی برای انجام وظایف بهینه‌سازی است؛ در رویکردهای تک‌عاملی، یک نمونه منفرد از مدل زبانی کل فرایند را به‌صورت خودکار و تکرارشونده به‌عهده دارد، در حالی‌که در رویکردهای چندعاملی، مسئولیت‌ها میان چند عامل تخصصی توزیع می‌شود تا هم‌افزایی، کارایی و توان حل مسئله افزایش یابد. همان‌گونه که در جدول~\ref{tab:recent-works} خلاصه شده است، این دوگانگی بر جنبه‌هایی همچون \persianfootnote{کدزایی}\LTRfootnote{Code Generation}، \persianfootnote{یکپارچه‌سازی دانش بیرونی}\LTRfootnote{External Knowledge Integration} و \persianfootnote{کاوش فضای جست‌وجو}\LTRfootnote{Search Space Exploration} اثرگذار است. در ادامه، آثار مرورشده مطابق این چارچوب تفکیک می‌شوند و دلالت‌های معماری و مشارکت‌های هر یک تبیین می‌گردد. برای هر اثر، روش‌شناسی بنیادین آن به‌اختصار و بر پایه گزارش‌های اصلی توصیف می‌شود.

\subsection{رویکردهای تک‌عاملی}
معماری‌های تک‌عاملی از یک مدل زبانی واحد برای مدیریت خودکار خط لوله بهینه‌سازی بهره می‌گیرند؛ معمولاً از طریق \persianfootnote{حلقه‌های خودبازتاب}\LTRfootnote{Self-reflection loops}، \persianfootnote{الگوریتم‌های تکاملی}\LTRfootnote{Evolutionary Algorithms (EAs)} یا راهبردهای \persianfootnote{دستور ورودی}\LTRfootnote{Prompting} مستقیم. این روش‌ها از نظر پیاده‌سازی ساده‌تر و از نظر محاسباتی کم‌هزینه‌ترند، زیرا سربار ارتباط میان‌عاملی را حذف می‌کنند؛ هرچند در وظایف پیچیده و چندبُعدی که از تنوع دیدگاه‌ها یا فروکاست ماژولی سود می‌برند، ممکن است دچار کاستی شوند.

\begin{description}
    \item[\cite{zhang2023usingLLMforHPO}:]
          در این رویکرد، یک عامل منفرد بر پایه توصیف‌های داده و مدل با دستور ورودی هدایت می‌شود تا پیکربندی‌های ابرپارامتری را به‌صورت تکرارشونده پیشنهاد و بر حسب بازخورد کارایی اصلاح کند؛ بدین‌ترتیب مدل زبانی به‌منزله تصمیم‌گیر در حلقه بهینه‌سازی عمل می‌کند. ارزیابی‌ها روی وظایفی مانند رگرسیون خطی، \persianfootnote{مسئلهٔ فروشندهٔ دوره‌گرد}\LTRfootnote{Traveling Salesman Problem (TSP)} و بهینه‌سازی دستور ورودی انجام شده و نشان می‌دهد که در سناریوهای کم‌هزینه، عملکردی رقابتی با \persianfootnote{بهینه‌سازی بیزی}\LTRfootnote{Bayesian Optimization} حاصل می‌شود، زیرا نیاز به ارزیابی‌های پرشمار مدل کاهش می‌یابد.

    \item[\cite{zheng2023GENIUS}:]
          با تکیه بر یک عامل منفرد (برای نمونه یک مدل هم‌تراز با \lr{GPT-4}) برای جست‌وجوی معماری،
          از توصیف‌های زبان طبیعی برای تولید و ارزیابی مستقیم معماری‌ها استفاده می‌شود و از پالایش تکرارشونده بدون تکیه بر الگوریتم‌های جست‌وجوی کلاسیک بهره می‌گیرد. \\
          نتایج روی معیارهایی چون \lr{NAS-Bench-201} نشان می‌دهد که با اتکاء به استدلال مدل در پیمایش و رتبه‌بندی معماری‌ها،
          و با اتکا به دستور ورودی \persianfootnote{بی‌نمونه/کم‌نمونه}\LTRfootnote{Zero-shot/Few-shot} می‌توان آموزش صریح را تا حدی دور زد و به کارایی رقابتی دست یافت.

    \item[\cite{LLMatic2024}:]
          این روش یک مدل زبانی واحد را با بهینه‌سازی \persianfootnote{کیفیت\textemdash‌تنوع}\LTRfootnote{Quality-Diversity (QD)} برای جست‌وجوی معماری ترکیب می‌کند؛ بدین‌صورت که مدل زبانی جهش‌های کُد-محورِ معماری را تولید و آن‌ها را در یک \persianfootnote{بایگانیِ تنوع‌محور}\LTRfootnote{Diversity-focused archive} ارزیابی می‌کند. تأکید روش بر جست‌وجوی تکاملی در فضای شبکه‌های عصبی است و نتایج در رده‌بندی تصاویر نشان می‌دهد که با آمیختن تنوعِ تولیدشده توسط مدل با سنجه‌های \persianfootnote{برازش}\LTRfootnote{Fitness} نسبت به \persianfootnote{جست‌وجوی تصادفی}\LTRfootnote{Random Search} بهبود حاصل می‌شود.

    \item[\cite{sarah2024llamaNAS}:]
          این رویکرد با تکیه بر یک مدل زبانی واحدِ مبتنی بر خانوادهٔ \persianfootnote{لاما}\LTRfootnote{LLaMA}، معماری‌های فشرده و کارآمد را برای خودِ مدل‌های زبانی پیشنهاد می‌کند؛ با استفاده از \persianfootnote{جست‌وجوی بی‌گرادیان}\LTRfootnote{Gradient-free Search} و \persianfootnote{قیود آگاه به سخت‌افزار}\LTRfootnote{Hardware-aware Constraints}. ارزیابی‌ها در وظایف مدل‌سازی زبان نشان می‌دهد که با نمونه‌برداری و ارزیابی تکرارشونده و بدون آموزش کامل، هزینهٔ جست‌وجو کاهش یافته و دقت رقابتی حفظ می‌شود.

    \item[\cite{ji2025RZNAS}:]
          چارچوبی تک‌عاملی که جست‌وجوی هدایت‌شده توسط مدل زبانی را با راهبرد «\persianfootnote{صفرهزینهٔ بازتابی}\LTRfootnote{Reflective Zero-cost}» تقویت می‌کند؛ به‌گونه‌ای که مدل زبانی معماری‌ها را پیشنهاد و بر پایهٔ جانشین‌های بی‌هزینه مانند \persianfootnote{جریان سیناپسی}\LTRfootnote{Synaptic Flow} آن‌ها را سریع ارزیابی و جهت جست‌وجو را در \persianfootnote{حلقه‌های بازتاب}\LTRfootnote{Reflection Loops} اصلاح می‌کند. نتایج در \lr{CIFAR-10} و \lr{ImageNet} نشان می‌دهد که همگرایی سریع‌تر و معماری‌های بهتری نسبت به خطوط پایهٔ مبتنی بر مدل زبانی حاصل می‌شود.

    \item[\cite{chen2023Evoprompting}:]
          با الهام از \persianfootnote{الگوریتم‌های ژنتیکی}\LTRfootnote{Genetic Algorithms}، پرامپت‌ها برای یک عامل منفرد به‌صورت جمعیتی تکامل می‌یابند (جهش و ترکیب) تا کُدِ شبکه‌های عصبی تولید شود و سپس روی وظایفی چون طبقه‌بندی تصویر ارزیابی می‌گردد. این رویکرد با بهبود تدریجی جمعیتِ پرامپت‌ها، بدون نیاز به ابزارهای بیرونی، نتایج قدرتمندی در معیارهای جست‌وجوی معماری شبکه‌های عصبی به‌دست می‌دهد.

    \item[\cite{zhang2023AutomlGPTAutomaticMachineLearning}:]
          خط لوله‌ای تک‌عاملی که با تکیه بر یک مدل زبانی، کل فرایند یادگیری ماشین را خودکار می‌سازد: از تولید کُدِ پیش‌پردازش و انتخاب مدل تا ارزیابی. سامانه از حلقه‌های بازخورد تکرارشونده برای پالایش بهره می‌برد و در داده‌های جدولی نشان می‌دهد که خودکارسازی سراسریِ قابل قیاس با کاردان‌های انسانی ممکن است؛ با تأکید بر نقش مدل زبانی در کُدزایی و تنظیم ابرپارامترها.

    \item[\cite{Yu2025GPTNAS}:]
          تلفیق یک مدل واحدِ \lr{GPT} با الگوریتم‌های تکاملی برای جست‌وجوی معماری؛ بدین‌گونه که معماری‌ها به‌صورت دستور ورودی کُدگذاری‌شده و از رهگذر انتخاب و جهش تکامل می‌یابند. ارزیابی‌ها در طبقه‌بندی تصویر (برای مثال \lr{CIFAR-10}) نشان می‌دهد که با تکیه بر پیش‌ـ‌آموزش مولد، تنوع معماری‌ها بدون کُدزایی صریح افزایش یافته و نسبت به الگوریتم‌های تکاملی کلاسیک، سرعت همگرایی بهبود می‌یابد.
\end{description}

\subsection{رویکردهای چندعاملی}
در معماری‌های چندعاملی، وظایف میان چندین نمونه از مدل‌های زبانی یا عوامل تخصصی تفکیک می‌شود تا جریان‌های کاریِ مشارکتی مانند برنامه‌ریزی، اجرا و نقادی شکل گیرد. این سازوکار که به کار تیمی انسانی شباهت دارد، با افزایش تاب‌آوری و توان مدیریت پیچیدگی همراه است؛ هرچند چالش‌هایی چون سربار هماهنگی و ناهمخوانیِ تعاملات میان عوامل را نیز به‌همراه دارد.

\begin{description}
    \item[\cite{xu2024largeTextToML}:]
          چارچوبی چندعاملی که با ترجمهٔ توصیف‌های زبانیِ وظایف به خط‌ لوله‌های اجرایی یادگیری ماشین، نقش‌های برنامه‌ریز، کُدزای و ارزیاب را میان عوامل توزیع می‌کند. تنظیم ابرپارامتر و انتخاب مدل به‌صورت خودکار و عمدتاً در سناریوهای بی‌نمونه انجام می‌شود و آزمایش‌ها در مجموعه‌داده‌های متنوع نشان‌دهندهٔ سودمندی هم‌افزایی عوامل است.

    \item[\cite{liu2025agenthpo}:]
          چند عامل با نقش‌های پیشنهاددهنده، ارزیاب و بهینه‌ساز در قالب گفت‌وگوهای تکرارشونده برای پیشنهاد و پالایش ابرپارامترها همکاری می‌کنند. بر پایهٔ مطالعات تجربی در شبکه‌های عمیق، این چارچوب بدون اتکا به کُدزایی، تنظیمی رقابتی در وظایفی چون بازشناسی تصویر ارائه می‌دهد و فضای جست‌وجو را به‌صورت کارآمد می‌کاود.

    \item[\cite{trirat2025automlagent}:]
          چارچوبی چندعاملی برای خودکارسازی سراسر فرایند است. این چارچوب با عوامل تخصصی در پیش‌پردازش داده، طراحی مدل و بهینه‌سازی کار می‌کند و از دانش بیرونی و کُدزایی بهره می‌گیرد.
          با پرامپت‌گذاری بی‌نمونه و ارزیابی روی معیارهایی چون \lr{OpenML}، نسبت به روش‌های تک‌عاملی کارایی برتری نشان می‌دهد و پالایش ماژولیِ مشارکتی را میسر می‌سازد.

    \item[\cite{liu2024LLAMBO}:]
          ادغام بهینه‌سازی بیزی با سامانه‌ای چندعاملی؛ عوامل به بهبود \persianfootnote{مدل‌سازی جانشین}\LTRfootnote{Surrogate Modeling} و \persianfootnote{تابع اکتساب}\LTRfootnote{Acquisition Function} در تنظیم ابرپارامتر کمک می‌کنند و با اتکا به توان بی‌نمونه، شمار ارزیابی‌ها را کاهش می‌دهند. نتایج در توابع جعبه‌سیاه و شبکه‌های عصبی نشان می‌دهد که استدلال زبانیِ عوامل می‌تواند حلقهٔ بیزی را راهبری کند.

    \item[\cite{Yang_2025_NADER}:]
          رویکردی چندعاملی برای جست‌وجوی معماری که طراحی سلسله‌مراتبی را از طریق ساختارهای درختی پیش می‌برد و از دانش بیرونی برای پالایش بهره می‌گیرد. فرآیند چندمرحله‌ایِ پیشنهاد، ارزیابی و اصلاح معماری‌ها با مذاکرهٔ میان عوامل همراه است و در وظایف بینایی رایانه‌ای نشان‌دهندهٔ مقیاس‌پذیری جست‌وجو از رهگذر اشتراک دانش است.

    \item[\cite{shen2023HuggingGPT}:]
          سامانه‌ای چندعاملی با محوریت یک ChatGPT که وظایف پیچیده را به زیروظایف تفکیک کرده و با عوامل تخصصی که از مدل‌های \lr{Hugging Face} از طریق واسط‌های برنامه‌نویسی بهره می‌گیرند، یکپارچه می‌سازد. ارزیابی‌ها در وظایف چندوجهی نشان می‌دهد که برنامه‌ریزی عاملی و اتصال ابزارها می‌تواند خودکارسازی کارای جریان‌های پیچیده را رقم بزند.

    \item[\cite{zhang-etal-2024-MLCopilot}:]
          چارچوبی چندعاملی که عواملِ تحلیل داده، انتخاب مدل و رفع خطا را با تکیه بر یکپارچه‌سازی دانش بیرونی به‌کار می‌گیرد. تمرکز روش بر جریان‌های کاریِ مکالمه‌محور و بدون کُدزایی است و آزمایش‌ها در مجموعه‌داده‌های مرسوم نشان می‌دهد که همکاری میان عوامل، حل مسئله را حتی در فضاهای جست‌وجوی محدود ارتقاء می‌دهد.
\end{description}

% \paragraph{جمع‌بندی و چشم‌انداز.}
این طبقه‌بندیِ عامل‌محور بر گرایشی فزاینده به سوی \persianfootnote{ساختارهای ترکیبی}\LTRfootnote{Hybrid Architectures} در بهینه‌سازیِ هدایت‌شده توسط مدل‌های زبانی دلالت دارد. روش‌های تک‌عاملی در سناریوهای ساده‌تر یا محدود به منابع، غالب‌اند؛ در حالی‌که الگوهای چندعاملی به‌سبب مقیاس‌پذیری در مدیریت چالش‌های چندوجهیِ یادگیری ماشین خودکار در حال فربودن هستند. مسیرهای آینده می‌تواند شامل سازوکارهای سازگار برای جابجایی پویا میان این معماری‌ها یا بهره‌گیری از ساختارهای سلسله‌مراتبیِ عاملی باشد تا کارایی در حوزه‌های جست‌وجوی معماری، تنظیم ابرپارامتر و فراتر از آن بهینه‌تر شود.