
\section{تحلیل بر مبنای معماری عامل}

\subsection{سامانه‌های تک‌عاملی}

بیشینهٔ سامانه‌های مبتنی بر مدل‌های زبانی بزرگ برای خودکارسازی یادگیری ماشین، معماری‌های تک‌عاملی را برمی‌گزینند که در آن یک عامل منفرد کل جریان بهینه‌سازی را مدیریت می‌کند. بر مبنای چگونگی ادغام مدل زبانی در فرایند بهینه‌سازی، این سامانه‌ها در چند پارادایم عملیاتی متمایز قرار می‌گیرند.

\subsubsection{\persianfootnote{بهینه‌سازی مستقیم از طریق دستوردهی تکراری}\protect\LTRfootnote{Direct Optimization through Iterative Prompting}}
در این رویکرد برجسته، مدل‌های زبانی به‌منزلهٔ بهینه‌سازهای \persianfootnote{جعبه‌سیاه}\LTRfootnote{black-box} به‌کار می‌روند که پیکربندی‌ها را پیشنهاد می‌کنند و از راه \persianfootnote{حلقه‌های بازخورد}\LTRfootnote{feedback loops} آن‌ها را پالایش می‌کنند. مدل با تکیه بر تاریخچهٔ \persianfootnote{آزمون‌ها}\LTRfootnote{trial} که به‌صورت \persianfootnote{گفت‌وگوهای چت}\LTRfootnote{chat-style dialogues} یا خلاصه‌های فشرده انباشته می‌شود، \persianfootnote{زمینه}\LTRfootnote{context} را حفظ می‌کند و پالایش تکراری مبتنی بر معیارهای اعتبارسنجی را ممکن می‌سازد \cite{zhang2023usingLLMforHPO, zheng2023GENIUS}. این پارادایم به چارچوب‌های بهینه‌سازی \persianfootnote{بیزی}\LTRfootnote{Bayesian} نیز بسط یافته است؛ جایی که مدل‌های آغاز گرم، نمونه‌گیری از نامزدها و \persianfootnote{مدل‌سازی جانشین}\LTRfootnote{surrogate modeling} را با اتکاء به استدلال زبان طبیعی و مشروط بر تاریخچهٔ بهینه‌سازی انجام می‌دهند \cite{liu2024LLAMBO}. این رویکردها در تنظیمات با بودجه کم کارایی رقابتی نشان می‌دهند و بی‌آن‌که به \persianfootnote{ریزتنظیم}\LTRfootnote{fine-tuning} نیاز داشته باشند، بر \persianfootnote{یادگیری زمینه ای}\LTRfootnote{in-context learning} از توصیف مسئله و بازخورد تجربی تکیه می‌کنند.

\subsubsection{\persianfootnote{عملگرهای تکاملی}\protect\LTRfootnote{Evolutionary Operators}}
راهبردی دیگر، مدل زبانی را به‌عنوان عملگرهای \persianfootnote{جهش}\LTRfootnote{mutation} یا \persianfootnote{ترکیب}\LTRfootnote{crossover} درون چارچوب‌های \persianfootnote{تکاملی}\LTRfootnote{evolutionary} جا می‌دهد. به‌جای جایگزینی الگوریتم‌های جست‌وجوی سنتی، این سامانه‌ها آن‌ها را با تنوع‌های تولیدشده توسط مدل زبانی تقویت می‌کنند. مدل می‌تواند تغییرات معماری مبتنی بر کد را در چارچوب‌های \persianfootnote{کیفیت–تنوع}\LTRfootnote{quality-diversity} بسازد \cite{LLMatic2024} یا به‌صورت عملگرهای \persianfootnote{تطبیقی}\LTRfootnote{adaptive operators} که میان نسل‌ها با \persianfootnote{تنظیم دستور}\LTRfootnote{prompt-tuning} پالایش می‌شوند عمل کند \cite{chen2023Evoprompting}. برخی پیاده‌سازی‌ها \persianfootnote{توانایی‌های بازتابی}\LTRfootnote{reflective capabilities} را نیز می‌گنجانند؛ به این معنا که مدل پیامدهای جهش را تحلیل می‌کند و \persianfootnote{بازخورد زبانی}\LTRfootnote{linguistic feedback} برای هدایت تکرارهای بعدی تولید می‌کند \cite{ji2025RZNAS}. این ادغام، \persianfootnote{پایداری}\LTRfootnote{robustness} جست‌وجوی تکاملی را حفظ می‌کند و در عین حال از \persianfootnote{خلاقیت}\LTRfootnote{creativity} مدل در تولید تنوع‌های معنادار بهره می‌گیرد.

\subsubsection{\persianfootnote{کنترل‌گرهای جریان کار}\protect\LTRfootnote{Workflow Controllers}}
در این پارادایم، مدل‌های زبانی به‌مثابه \persianfootnote{هماهنگ‌کننده}\LTRfootnote{orchestrator} برای مدیریت اجزای \persianfootnote{خطّ لوله}\LTRfootnote{pipeline} به کار می‌روند. سامانه با ترکیب دستور‌هایی که \persianfootnote{فرادادهٔ ساختاریافته}\LTRfootnote{structured metadata}-از جمله \persianfootnote{کارت‌های داده}\LTRfootnote{data cards} و \persianfootnote{کارت‌های مدل}\LTRfootnote{model cards}-را در خود دارند، مدل را در مراحل پیاپی از پردازش داده، انتخاب مدل تا تنظیم فراپارامتر هدایت می‌کند \cite{zhang2023AutomlGPTAutomaticMachineLearning, shen2023HuggingGPT}. برخی پیاده‌سازی‌ها برنامه‌های پیچیدهٔ یادگیری ماشین را به \persianfootnote{مولفه‌های ماژولار}\LTRfootnote{modular components} تجزیه می‌کنند که به‌طور جداگانه تولید و با \persianfootnote{آزمون‌های واحد خودکار}\LTRfootnote{automated unit tests} راستی‌آزمایی می‌شوند تا سازگاری تضمین گردد \cite{xu2024largeTextToML}. این رویکرد با شکستن خطوط لولهٔ طولانی و ناهمگون به زیروظایف قابل مدیریت و اتکاء به \persianfootnote{دستوردهی زمینه‌مند}\LTRfootnote{contextual prompting}، انسجام کلّی را حفظ می‌کند.

\subsubsection{\persianfootnote{بازسازی معماری}\protect\LTRfootnote{Architecture Reconstruction}}
در این دسته، مدل‌های زبانی تخصصی بر روی معماری‌های عصبی \persianfootnote{کدگذاری‌شده}\LTRfootnote{encoded} آموزش می‌بینند تا روش‌های جست‌وجوی سنتی را تقویت کنند. به‌جای انجام مستقیم جست‌وجو، این سامانه‌ها می‌آموزند \persianfootnote{مشخصات معماری}\LTRfootnote{architecture specifications} نمونه‌برداری‌شده توسط \persianfootnote{الگوریتم‌های ژنتیک}\LTRfootnote{genetic algorithms} را بازسازی یا تکمیل کنند و بدین‌وسیله کاستی‌های \persianfootnote{عملگرهای سنتی}\LTRfootnote{traditional operators} را با اصول طراحی آموخته‌شده جبران کنند \cite{Yu2025GPTNAS}. این رویکرد ترکیبی کارایی جست‌وجوی الگوریتمی را حفظ کرده و آن را با تشخیص الگو تقویت می‌کند.

\subsection{سامانه‌های چندعاملی}

معماری‌های چندعاملی با تفکیک نقش، زیروظایف یادگیری ماشین خودکار را میان عامل‌هایی با قابلیت‌های مکمل توزیع می‌کنند. این سامانه‌ها از \persianfootnote{رهگذر تفکیک کارکردی}\LTRfootnote{functional decomposition} و \persianfootnote{همکاری بین‌عاملی}\LTRfootnote{inter-agent collaboration}، مدیریت پیچیدگی و استدلال پیچیده‌تر را ممکن می‌سازند.

\subsubsection{\persianfootnote{همکاری مبتنی بر نقش}\protect\LTRfootnote{Role-Based Collaboration}}
الگوی پایه، دو عامل تخصصی با مسئولیت‌های متمایز را به‌کار می‌گیرد. در یک ساختار، تولید \persianfootnote{پیکربندی}\LTRfootnote{configuration} از اجرای تجربی جدا می‌شود: عامل سازنده نیازمندی‌ها را تفسیر و پیکربندی‌های پیشنهادی همراه با استدلال ارائه می‌کند و عامل اجراکننده آموزش را انجام داده و نتایج را در گزارش‌های مشترک می‌گنجاند تا چرخه‌های بعدی پیشنهادهای سازنده را تغذیه کند \cite{liu2025agenthpo}. این تقسیم کار بازتاب گردش‌کار متخصصان است و با \persianfootnote{حافظهٔ ترتیبی}\LTRfootnote{episodic memory} انباشته، به عملکرد خودگردان بدون مداخلهٔ انسانی می‌انجامد.

\subsubsection{\persianfootnote{هماهنگی سلسله‌مراتبی}\protect\LTRfootnote{Hierarchical Coordination}}
در ساختارهای پیچیده‌تر، چند عامل تخصصی تحت نظارت یک \persianfootnote{مدیر عامل}\LTRfootnote{Agent Manager} سازمان می‌یابند. مدیر با \persianfootnote{استدلال تقویت‌شده با بازیابی}\LTRfootnote{retrieval-augmented reasoning} طرح‌های متنوعی می‌سازد، آن‌ها را به زیروظایف \persianfootnote{قابل موازی‌سازی}\LTRfootnote{parallelizable subtasks} واگشایی و به عامل مناسب تخصیص می‌دهد و از رهگذر راستی‌آزمایی چندمرحله‌ای و \persianfootnote{حلقه‌های بازنگری}\LTRfootnote{revision loops} نتایج را اعتبارسنجی می‌کند \cite{trirat2025automlagent}. این معماری کلّ خط لولهٔ AutoML را از بازیابی داده تا \persianfootnote{استقرار}\LTRfootnote{deployment} به‌صورت کارآمد پیش می‌برد و \persianfootnote{وابستگی‌های بین‌گامی}\LTRfootnote{inter-step dependencies} را با \persianfootnote{پروتکل‌های هماهنگی ساختاریافته}\LTRfootnote{structured coordination protocols} مدیریت می‌کند.

\subsubsection{\persianfootnote{تیم‌های پژوهش–توسعه}\protect\LTRfootnote{Research-Development Teams}.}
پیشرفته‌ترین ساختار سازمانی، عامل‌ها را در تیم‌های کارکردی تقسیم می‌کند \cite{Yang2025NADER}. \persianfootnote{تیم پژوهش}\LTRfootnote{Research Team} دانش را از \persianfootnote{ادبیات پژوهشی}\LTRfootnote{literature} استخراج می‌کند و با اتکاء به بینش‌های بازیابی‌شده، پیشنهادهای تغییر را می‌سازد؛ \persianfootnote{تیم توسعه}\LTRfootnote{Development Team} این تغییرها را بر \persianfootnote{نمایش‌های گراف}\LTRfootnote{graph representations} اعمال کرده و هم بازخورد فوری و هم استخراج تجربهٔ بلندمدت را فراهم می‌کند. گفت‌وگوهای چندمرحله‌ای میان تیم‌ها یادگیری مستمر از تاریخچهٔ طراحی را ممکن می‌کند و \persianfootnote{پایگاه‌های دادهٔ برداری}\LTRfootnote{vector databases} با \persianfootnote{بازیابی مبتنی بر شباهت}\LTRfootnote{similarity-based retrieval}، دانش و تجربه‌های گذشتهٔ مرتبط را برای هدایت اکتشاف فراخوانی می‌کنند.

پارادایم چندعاملی با افزودن پیچیدگی هماهنگی، در برابر \persianfootnote{توضیح‌پذیری}\LTRfootnote{interpretability} بهبود‌یافته از طریق تفکیک صریح نقش‌ها و کارایی بهتر بهینه‌سازی از رهگذر استدلال تخصصی معامله می‌کند؛ هرچند به مدیریت حافظه پیشرفته برای حفظ سازگاری در تعاملات عامل‌ها و طراحی دقیق پروتکل‌های ارتباطی برای جلوگیری از شکست‌های هماهنگی نیاز دارد.
